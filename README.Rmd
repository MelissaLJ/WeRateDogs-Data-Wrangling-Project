
## 引言
该项目基于推特WeRateDogs档案数据，通过网络下载获取档案图像预测数据，通过推特API获取转发和点赞数据，评估数据质量和整洁度问题，并进行清洗工作，最终得到了可用于数据分析和可视化的干净数据集twitter_archive_master.csv。

## 安装
该项目数据收集、评估和清洗工作均是在Jupyter Notebook中完成，需要通过pip或者Anaconda安装该编辑器。

## 使用

#### 导入库
import pandas as pd
import numpy as np
import requests
import tweepy
import json
import re
import matplotlib.pyplot as plt 
%matplotlib inline

#### 数据收集
WeRateDogs推特档案的基础数据来源于项目提供，而推特图像的预测数据是通过Python提供的Requests库及url编程下载得到，额外附加数据例如转发数和赞数是使用Python通过Tweepy库查询API中推特的JSON数据获取的。

#### 数据评估
数据集以dataframe格式导入Jupyter Notebook后，主要从两点评估数据：整洁度和质量；

通过观察dataframe各列的含义以及所收集到的三个数据片段的结构与内容，发现两个整洁度问题，一个是数据集的宽格式不利用分析，另一个是三个数据片段同属一个观察单位，不应该孤立考察；

通过考察dataframe各列数据类型、重复值、缺失值以及异常值情况,发现了8个质量问题，包括数据类型错误，文本提取错误等。因为该项目最初的数据集是从文本格式的档案中提取的，提取过程中由于没有充分考虑文本结构造成不完整或者错误，所以本项目主要的数据问题是信息提取的问题。

#### 数据清洗

数据集重塑，宽格式到长格式的转换（利用融合函数pd.melt或者直接提取文本信息后创建新列删除旧列）；
数据集片段的合并（利用pd.merge函数）；
更改错误的数据类型（利用pd.to_datetime转换为时间戳，也可以利用astype函数转换数值型和字符型变量）；
仔细的考察原文本文字结构与待提取信息的要求，利用正则表达式调整提取公式，使得提取的数据完整而正确（利用Series的字符串处理方法、正则表达式、列表表达式、lambda函数等）。

#### 数据存储
通过to_csv函数存储清洗后的数据集。

#### 数据可视化
通过matplotlib绘制散点图、柱状图和饼形图，对数据集进行简单的分析。

## 附言
该数据集作为Udacity学位实战项目，只针对10个数据问题进行了清理，所以仍存在其它数据问题待处理。
